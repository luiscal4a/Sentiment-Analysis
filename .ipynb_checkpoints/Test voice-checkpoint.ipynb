{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c0d1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emotion_recognition_repo_2 import emotion_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0abc0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "ANALYSED_EMOTIONS = ['sad', 'neutral', 'happy', 'fear', 'angry', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64907fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TESS&RAVDESS] There are 813 training audio files for category:sad\n",
      "[TESS&RAVDESS] There are 147 testing audio files for category:sad\n",
      "[TESS&RAVDESS] There are 586 training audio files for category:neutral\n",
      "[TESS&RAVDESS] There are 94 testing audio files for category:neutral\n",
      "[TESS&RAVDESS] There are 806 training audio files for category:happy\n",
      "[TESS&RAVDESS] There are 148 testing audio files for category:happy\n",
      "[TESS&RAVDESS] There are 818 training audio files for category:fear\n",
      "[TESS&RAVDESS] There are 142 testing audio files for category:fear\n",
      "[TESS&RAVDESS] There are 809 training audio files for category:angry\n",
      "[TESS&RAVDESS] There are 148 testing audio files for category:angry\n",
      "[TESS&RAVDESS] There are 512 training audio files for category:disgust\n",
      "[TESS&RAVDESS] There are 80 testing audio files for category:disgust\n",
      "[+] Generated TESS & RAVDESS DB CSV File\n",
      "[EMO-DB] Total files to write: 454\n",
      "[EMO-DB] Training samples: 363\n",
      "[EMO-DB] Testing samples: 90\n",
      "[+] Generated EMO-DB CSV File\n",
      "[Custom Dataset] There are 49 training audio files for category:neutral\n",
      "[Custom Dataset] There are 33 testing audio files for category:neutral\n",
      "[Custom Dataset] There are 48 training audio files for category:happy\n",
      "[Custom Dataset] There are 23 testing audio files for category:happy\n",
      "[Custom Dataset] There are 23 training audio files for category:fear\n",
      "[Custom Dataset] There are 23 testing audio files for category:fear\n",
      "[Custom Dataset] There are 23 training audio files for category:angry\n",
      "[Custom Dataset] There are 23 testing audio files for category:angry\n",
      "[Custom Dataset] There are 23 training audio files for category:disgust\n",
      "[Custom Dataset] There are 23 testing audio files for category:disgust\n",
      "[+] Generated Custom DB CSV File\n",
      "[+] Data loaded\n",
      "[+] Model trained\n"
     ]
    }
   ],
   "source": [
    "my_model = SVC(probability=True)\n",
    "# pass my model to EmotionRecognizer instance\n",
    "# and balance the dataset\n",
    "rec = emotion_recognition.EmotionRecognizer(model=my_model, emotions=ANALYSED_EMOTIONS, balance=True, verbose=1)\n",
    "# train the model\n",
    "rec.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ab2022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.49645390070921985\n",
      "Train score: 0.5511642156862745\n"
     ]
    }
   ],
   "source": [
    "print(\"Test score:\", rec.test_score())\n",
    "# check the train accuracy for that model\n",
    "print(\"Train score:\", rec.train_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(emotion_recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a669124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: {'angry': 0.02192156995758873, 'disgust': 0.07579819036990978, 'fear': 0.1125610416625493, 'happy': 0.15891939373198982, 'neutral': 0.2250501790402278, 'sad': 0.4057496252377342}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MIT Lab\\Lies\\emotion_recognition_repo_2\\utils.py:93: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00045776 -0.00036621\n",
      " -0.00042725] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction:\", rec.predict_proba(\"../Experiment/02-lie-long.wav\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
